{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_hourly</th>\n",
       "      <th>hourly</th>\n",
       "      <th>soil_temp1</th>\n",
       "      <th>temp1</th>\n",
       "      <th>solar_rd</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>soil_temp</th>\n",
       "      <th>temp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Wind_Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>293.431</td>\n",
       "      <td>292.019</td>\n",
       "      <td>1.961410e+07</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>1.399950</td>\n",
       "      <td>20.281</td>\n",
       "      <td>18.869</td>\n",
       "      <td>95848.4</td>\n",
       "      <td>1.408539</td>\n",
       "      <td>1.710245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>293.063</td>\n",
       "      <td>291.975</td>\n",
       "      <td>1.862650e-09</td>\n",
       "      <td>0.114499</td>\n",
       "      <td>1.303050</td>\n",
       "      <td>19.913</td>\n",
       "      <td>18.825</td>\n",
       "      <td>95901.0</td>\n",
       "      <td>1.308071</td>\n",
       "      <td>1.369762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>293.102</td>\n",
       "      <td>292.538</td>\n",
       "      <td>1.086020e+05</td>\n",
       "      <td>-0.272937</td>\n",
       "      <td>1.208260</td>\n",
       "      <td>19.952</td>\n",
       "      <td>19.388</td>\n",
       "      <td>95997.9</td>\n",
       "      <td>1.238704</td>\n",
       "      <td>1.163198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>295.555</td>\n",
       "      <td>295.004</td>\n",
       "      <td>8.415560e+05</td>\n",
       "      <td>-0.401350</td>\n",
       "      <td>1.049350</td>\n",
       "      <td>22.405</td>\n",
       "      <td>21.854</td>\n",
       "      <td>96101.7</td>\n",
       "      <td>1.123484</td>\n",
       "      <td>0.867866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>299.023</td>\n",
       "      <td>297.310</td>\n",
       "      <td>2.294920e+06</td>\n",
       "      <td>-0.516890</td>\n",
       "      <td>0.721392</td>\n",
       "      <td>25.873</td>\n",
       "      <td>24.160</td>\n",
       "      <td>96141.0</td>\n",
       "      <td>0.887458</td>\n",
       "      <td>0.427755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_hourly  hourly  soil_temp1    temp1      solar_rd       u10       v10  \\\n",
       "0   2011-01-01     1.0     293.431  292.019  1.961410e+07  0.155315  1.399950   \n",
       "1   2011-01-01     2.0     293.063  291.975  1.862650e-09  0.114499  1.303050   \n",
       "2   2011-01-01     3.0     293.102  292.538  1.086020e+05 -0.272937  1.208260   \n",
       "3   2011-01-01     4.0     295.555  295.004  8.415560e+05 -0.401350  1.049350   \n",
       "4   2011-01-01     5.0     299.023  297.310  2.294920e+06 -0.516890  0.721392   \n",
       "\n",
       "   soil_temp    temp  pressure  wind_speed  Wind_Energy  \n",
       "0     20.281  18.869   95848.4    1.408539     1.710245  \n",
       "1     19.913  18.825   95901.0    1.308071     1.369762  \n",
       "2     19.952  19.388   95997.9    1.238704     1.163198  \n",
       "3     22.405  21.854   96101.7    1.123484     0.867866  \n",
       "4     25.873  24.160   96141.0    0.887458     0.427755  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data from an Excel file\n",
    "data = pd.read_excel('Wind_Energy_Rayalaseema.xlsx')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " date_hourly        0\n",
      "hourly          95593\n",
      "soil_temp1          1\n",
      "temp1               0\n",
      "solar_rd            0\n",
      "u10                 0\n",
      "v10              1105\n",
      "soil_temp           1\n",
      "temp                1\n",
      "pressure         1105\n",
      "wind_speed          0\n",
      "Wind_Energy         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Remove rows with missing values (if desired)\n",
    "data = data.dropna()\n",
    "\n",
    "# Check for and remove duplicates (if desired)\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Outlier detection and handling (you can customize this)\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(data[['soil_temp', 'temp', 'pressure', 'wind_speed']]))\n",
    "threshold = 3\n",
    "outliers = (z_scores > threshold).all(axis=1)\n",
    "data = data[~outliers]\n",
    "\n",
    "# Data standardization (if not already done)\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Now, you can proceed with splitting the cleaned data and training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and target (y) from the cleaned dataset\n",
    "X = data[['soil_temp', 'temp', 'pressure', 'wind_speed']].values\n",
    "y = data['Wind_Energy'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the cleaned data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (if not already done)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Now you can proceed with building and training your model using the cleaned and split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and target (y) from the dataset\n",
    "X = data[['soil_temp', 'temp', 'pressure', 'wind_speed']].values\n",
    "y = data['Wind_Energy'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 1s/step - loss: 695.6073 - mae: 20.9034 - val_loss: 470.0452 - val_mae: 16.7644\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 694.5698 - mae: 20.8813 - val_loss: 469.3152 - val_mae: 16.7440\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 693.5358 - mae: 20.8594 - val_loss: 468.5914 - val_mae: 16.7237\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 692.4955 - mae: 20.8373 - val_loss: 467.8614 - val_mae: 16.7034\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 691.4468 - mae: 20.8149 - val_loss: 467.1277 - val_mae: 16.6831\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 690.3954 - mae: 20.7924 - val_loss: 466.3842 - val_mae: 16.6626\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 689.3362 - mae: 20.7696 - val_loss: 465.6393 - val_mae: 16.6420\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 688.2717 - mae: 20.7467 - val_loss: 464.8990 - val_mae: 16.6214\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 687.2038 - mae: 20.7237 - val_loss: 464.1466 - val_mae: 16.6005\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 686.1215 - mae: 20.7004 - val_loss: 463.3932 - val_mae: 16.5796\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 685.0351 - mae: 20.6771 - val_loss: 462.6379 - val_mae: 16.5586\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 683.9435 - mae: 20.6541 - val_loss: 461.8936 - val_mae: 16.5376\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 682.8430 - mae: 20.6309 - val_loss: 461.1278 - val_mae: 16.5164\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 681.7338 - mae: 20.6075 - val_loss: 460.3529 - val_mae: 16.4951\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 680.6215 - mae: 20.5847 - val_loss: 459.5733 - val_mae: 16.4735\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 679.5055 - mae: 20.5631 - val_loss: 458.7776 - val_mae: 16.4513\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 678.3693 - mae: 20.5410 - val_loss: 457.9722 - val_mae: 16.4290\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 677.2133 - mae: 20.5186 - val_loss: 457.1538 - val_mae: 16.4065\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 676.0482 - mae: 20.4959 - val_loss: 456.3201 - val_mae: 16.3837\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 674.8832 - mae: 20.4732 - val_loss: 455.4549 - val_mae: 16.3605\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 673.7353 - mae: 20.4506 - val_loss: 454.5861 - val_mae: 16.3372\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 672.5798 - mae: 20.4278 - val_loss: 453.7092 - val_mae: 16.3138\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 671.3981 - mae: 20.4046 - val_loss: 452.8553 - val_mae: 16.2906\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 670.1758 - mae: 20.3806 - val_loss: 451.9927 - val_mae: 16.2673\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 668.9297 - mae: 20.3561 - val_loss: 451.1041 - val_mae: 16.2434\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 667.6619 - mae: 20.3308 - val_loss: 450.1989 - val_mae: 16.2193\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 666.3764 - mae: 20.3050 - val_loss: 449.2796 - val_mae: 16.1951\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 665.0706 - mae: 20.2785 - val_loss: 448.3474 - val_mae: 16.1708\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 663.7420 - mae: 20.2523 - val_loss: 447.3879 - val_mae: 16.1460\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 662.3905 - mae: 20.2254 - val_loss: 446.4172 - val_mae: 16.1209\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 661.0220 - mae: 20.1980 - val_loss: 445.4351 - val_mae: 16.0956\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 659.6398 - mae: 20.1703 - val_loss: 444.4407 - val_mae: 16.0701\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 658.2368 - mae: 20.1419 - val_loss: 443.4351 - val_mae: 16.0445\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 656.8057 - mae: 20.1128 - val_loss: 442.4173 - val_mae: 16.0186\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 655.3464 - mae: 20.0829 - val_loss: 441.3873 - val_mae: 15.9924\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 653.8666 - mae: 20.0527 - val_loss: 440.3496 - val_mae: 15.9659\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 652.3682 - mae: 20.0220 - val_loss: 439.3091 - val_mae: 15.9393\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 650.8494 - mae: 19.9907 - val_loss: 438.2562 - val_mae: 15.9123\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 649.3098 - mae: 19.9590 - val_loss: 437.1921 - val_mae: 15.8852\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 647.7391 - mae: 19.9267 - val_loss: 436.1144 - val_mae: 15.8578\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 646.1425 - mae: 19.8937 - val_loss: 435.0237 - val_mae: 15.8301\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 644.4975 - mae: 19.8598 - val_loss: 433.9189 - val_mae: 15.8020\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 642.8219 - mae: 19.8253 - val_loss: 432.7992 - val_mae: 15.7735\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 641.1412 - mae: 19.7903 - val_loss: 431.6608 - val_mae: 15.7444\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 639.4297 - mae: 19.7547 - val_loss: 430.5082 - val_mae: 15.7149\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 637.6838 - mae: 19.7184 - val_loss: 429.3377 - val_mae: 15.6850\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 635.9041 - mae: 19.6827 - val_loss: 428.1407 - val_mae: 15.6544\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 634.0980 - mae: 19.6478 - val_loss: 426.9234 - val_mae: 15.6244\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 632.2640 - mae: 19.6122 - val_loss: 425.6767 - val_mae: 15.5958\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 630.3932 - mae: 19.5759 - val_loss: 424.4135 - val_mae: 15.5668\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 628.4761 - mae: 19.5387 - val_loss: 423.1346 - val_mae: 15.5374\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 626.5247 - mae: 19.5007 - val_loss: 421.8361 - val_mae: 15.5076\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 624.5363 - mae: 19.4619 - val_loss: 420.4953 - val_mae: 15.4783\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 622.5196 - mae: 19.4225 - val_loss: 419.1041 - val_mae: 15.4500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 620.4545 - mae: 19.3820 - val_loss: 417.6884 - val_mae: 15.4211\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 618.3505 - mae: 19.3407 - val_loss: 416.2429 - val_mae: 15.3917\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 616.1878 - mae: 19.2983 - val_loss: 414.7260 - val_mae: 15.3611\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 613.9715 - mae: 19.2547 - val_loss: 413.1624 - val_mae: 15.3297\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 611.7067 - mae: 19.2102 - val_loss: 411.5680 - val_mae: 15.2977\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 609.3973 - mae: 19.1661 - val_loss: 409.9509 - val_mae: 15.2652\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 607.0522 - mae: 19.1234 - val_loss: 408.3041 - val_mae: 15.2316\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 604.6696 - mae: 19.0797 - val_loss: 406.6204 - val_mae: 15.1973\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 602.2408 - mae: 19.0362 - val_loss: 404.9138 - val_mae: 15.1623\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 599.7592 - mae: 18.9943 - val_loss: 403.1811 - val_mae: 15.1267\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 597.2324 - mae: 18.9513 - val_loss: 401.4228 - val_mae: 15.0905\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 594.6699 - mae: 18.9075 - val_loss: 399.6385 - val_mae: 15.0536\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 592.0707 - mae: 18.8628 - val_loss: 397.8290 - val_mae: 15.0162\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 589.4337 - mae: 18.8172 - val_loss: 395.9945 - val_mae: 14.9781\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 586.7607 - mae: 18.7707 - val_loss: 394.1182 - val_mae: 14.9389\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 584.0490 - mae: 18.7233 - val_loss: 392.1847 - val_mae: 14.8984\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 581.3027 - mae: 18.6751 - val_loss: 390.2188 - val_mae: 14.8571\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 578.5179 - mae: 18.6260 - val_loss: 388.2199 - val_mae: 14.8149\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 575.6934 - mae: 18.5762 - val_loss: 386.1889 - val_mae: 14.7719\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 572.8127 - mae: 18.5255 - val_loss: 384.1231 - val_mae: 14.7283\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 569.8918 - mae: 18.4738 - val_loss: 382.0276 - val_mae: 14.6841\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 566.9344 - mae: 18.4211 - val_loss: 379.9041 - val_mae: 14.6391\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 563.9398 - mae: 18.3676 - val_loss: 377.7515 - val_mae: 14.5937\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 560.8990 - mae: 18.3129 - val_loss: 375.5587 - val_mae: 14.5479\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 557.8196 - mae: 18.2572 - val_loss: 373.3310 - val_mae: 14.5012\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 554.7033 - mae: 18.2023 - val_loss: 371.0739 - val_mae: 14.4537\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 551.5483 - mae: 18.1499 - val_loss: 368.7869 - val_mae: 14.4053\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 548.3568 - mae: 18.0995 - val_loss: 366.4716 - val_mae: 14.3562\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 545.1299 - mae: 18.0513 - val_loss: 364.1250 - val_mae: 14.3059\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 541.8613 - mae: 18.0021 - val_loss: 361.7493 - val_mae: 14.2545\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 538.5598 - mae: 17.9520 - val_loss: 359.3497 - val_mae: 14.2022\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 535.2243 - mae: 17.9010 - val_loss: 356.9220 - val_mae: 14.1491\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 531.8498 - mae: 17.8491 - val_loss: 354.4475 - val_mae: 14.0951\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 528.4365 - mae: 17.7962 - val_loss: 351.9389 - val_mae: 14.0403\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 524.9909 - mae: 17.7425 - val_loss: 349.4022 - val_mae: 13.9849\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 521.5142 - mae: 17.6878 - val_loss: 346.8376 - val_mae: 13.9288\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 518.0051 - mae: 17.6322 - val_loss: 344.2454 - val_mae: 13.8719\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 514.4646 - mae: 17.5756 - val_loss: 341.6259 - val_mae: 13.8143\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 510.8942 - mae: 17.5180 - val_loss: 338.9790 - val_mae: 13.7558\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 507.2917 - mae: 17.4595 - val_loss: 336.3038 - val_mae: 13.6963\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 503.6608 - mae: 17.4001 - val_loss: 333.5987 - val_mae: 13.6359\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 500.0027 - mae: 17.3398 - val_loss: 330.8671 - val_mae: 13.5747\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 496.3182 - mae: 17.2785 - val_loss: 328.1100 - val_mae: 13.5127\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 492.6089 - mae: 17.2164 - val_loss: 325.3284 - val_mae: 13.4542\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 488.8758 - mae: 17.1533 - val_loss: 322.5225 - val_mae: 13.3950\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 485.1187 - mae: 17.0893 - val_loss: 319.6929 - val_mae: 13.3351\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 481.3390 - mae: 17.0244 - val_loss: 316.8417 - val_mae: 13.2744\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 477.5410 - mae: 16.9595 - val_loss: 313.9716 - val_mae: 13.2130\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 473.7201 - mae: 16.9012 - val_loss: 311.0784 - val_mae: 13.1508\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 469.8734 - mae: 16.8461 - val_loss: 308.1624 - val_mae: 13.0877\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 466.0083 - mae: 16.7904 - val_loss: 305.2242 - val_mae: 13.0237\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 462.1221 - mae: 16.7339 - val_loss: 302.2643 - val_mae: 12.9604\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 458.2169 - mae: 16.6765 - val_loss: 299.2832 - val_mae: 12.9024\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 454.2920 - mae: 16.6182 - val_loss: 296.2808 - val_mae: 12.8434\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 450.3497 - mae: 16.5590 - val_loss: 293.2594 - val_mae: 12.7835\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 446.3914 - mae: 16.4990 - val_loss: 290.2156 - val_mae: 12.7229\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 442.4212 - mae: 16.4380 - val_loss: 287.1548 - val_mae: 12.6614\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 438.4390 - mae: 16.3762 - val_loss: 284.0780 - val_mae: 12.5992\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 434.4442 - mae: 16.3134 - val_loss: 280.9860 - val_mae: 12.5363\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 430.4379 - mae: 16.2495 - val_loss: 277.8805 - val_mae: 12.4727\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 426.4219 - mae: 16.1846 - val_loss: 274.7603 - val_mae: 12.4084\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 422.3981 - mae: 16.1186 - val_loss: 271.6255 - val_mae: 12.3433\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 418.3677 - mae: 16.0516 - val_loss: 268.4771 - val_mae: 12.2775\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 414.3292 - mae: 15.9836 - val_loss: 265.3184 - val_mae: 12.2111\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 410.2850 - mae: 15.9145 - val_loss: 262.1502 - val_mae: 12.1439\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 406.2349 - mae: 15.8443 - val_loss: 258.9738 - val_mae: 12.0760\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 402.1808 - mae: 15.7731 - val_loss: 255.7894 - val_mae: 12.0075\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 398.1259 - mae: 15.7008 - val_loss: 252.5972 - val_mae: 11.9382\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 394.0677 - mae: 15.6276 - val_loss: 249.3983 - val_mae: 11.8683\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 390.0086 - mae: 15.5533 - val_loss: 246.1932 - val_mae: 11.7976\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 385.9420 - mae: 15.4780 - val_loss: 242.9817 - val_mae: 11.7262\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 381.8739 - mae: 15.4032 - val_loss: 239.7669 - val_mae: 11.6542\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 377.8055 - mae: 15.3277 - val_loss: 236.5492 - val_mae: 11.5814\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 373.7380 - mae: 15.2512 - val_loss: 233.3303 - val_mae: 11.5079\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 369.6713 - mae: 15.1736 - val_loss: 230.1121 - val_mae: 11.4338\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 365.6085 - mae: 15.0950 - val_loss: 226.8953 - val_mae: 11.3592\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 361.5474 - mae: 15.0154 - val_loss: 223.6809 - val_mae: 11.2841\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 357.4829 - mae: 14.9349 - val_loss: 220.4699 - val_mae: 11.2084\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 353.4200 - mae: 14.8541 - val_loss: 217.2637 - val_mae: 11.1322\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 349.3562 - mae: 14.7721 - val_loss: 214.0567 - val_mae: 11.0552\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 345.2968 - mae: 14.6890 - val_loss: 210.8505 - val_mae: 10.9776\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 341.2419 - mae: 14.6047 - val_loss: 207.6524 - val_mae: 10.8993\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 337.1884 - mae: 14.5193 - val_loss: 204.4641 - val_mae: 10.8208\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 333.1333 - mae: 14.4326 - val_loss: 201.2852 - val_mae: 10.7417\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 329.0810 - mae: 14.3447 - val_loss: 198.1168 - val_mae: 10.6620\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 325.0342 - mae: 14.2557 - val_loss: 194.9551 - val_mae: 10.5817\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 320.9938 - mae: 14.1656 - val_loss: 191.8050 - val_mae: 10.5009\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 316.9568 - mae: 14.0742 - val_loss: 188.6647 - val_mae: 10.4196\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 312.9253 - mae: 13.9817 - val_loss: 185.5209 - val_mae: 10.3373\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 308.9018 - mae: 13.8881 - val_loss: 182.3904 - val_mae: 10.2546\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 304.8828 - mae: 13.7934 - val_loss: 179.2768 - val_mae: 10.1714\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 300.8698 - mae: 13.6975 - val_loss: 176.1805 - val_mae: 10.0878\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 296.8644 - mae: 13.6006 - val_loss: 173.1024 - val_mae: 10.0039\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 292.8669 - mae: 13.5027 - val_loss: 170.0434 - val_mae: 9.9195\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 288.8752 - mae: 13.4037 - val_loss: 166.9990 - val_mae: 9.8344\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 284.8910 - mae: 13.3036 - val_loss: 163.9706 - val_mae: 9.7489\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 280.9153 - mae: 13.2034 - val_loss: 160.9628 - val_mae: 9.6629\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 276.9484 - mae: 13.1032 - val_loss: 157.9636 - val_mae: 9.5762\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 272.9839 - mae: 13.0020 - val_loss: 154.9850 - val_mae: 9.4891\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 269.0185 - mae: 12.8997 - val_loss: 152.0288 - val_mae: 9.4016\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 265.0554 - mae: 12.7964 - val_loss: 149.1007 - val_mae: 9.3186\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 261.0988 - mae: 12.6919 - val_loss: 146.1981 - val_mae: 9.2401\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 257.1494 - mae: 12.5865 - val_loss: 143.3204 - val_mae: 9.1650\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 253.2067 - mae: 12.4826 - val_loss: 140.4555 - val_mae: 9.0953\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 249.2627 - mae: 12.3781 - val_loss: 137.5967 - val_mae: 9.0249\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 245.3279 - mae: 12.2724 - val_loss: 134.7595 - val_mae: 8.9540\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 241.4059 - mae: 12.1658 - val_loss: 131.9479 - val_mae: 8.8829\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 237.4974 - mae: 12.0582 - val_loss: 129.1635 - val_mae: 8.8115\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 233.6033 - mae: 11.9497 - val_loss: 126.4072 - val_mae: 8.7399\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 229.7257 - mae: 11.8402 - val_loss: 123.6793 - val_mae: 8.6681\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 225.8566 - mae: 11.7304 - val_loss: 120.9797 - val_mae: 8.5962\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 221.9997 - mae: 11.6221 - val_loss: 118.3029 - val_mae: 8.5239\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 218.1529 - mae: 11.5127 - val_loss: 115.6493 - val_mae: 8.4511\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 214.3207 - mae: 11.4023 - val_loss: 113.0128 - val_mae: 8.3778\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 210.4993 - mae: 11.2908 - val_loss: 110.4044 - val_mae: 8.3042\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 206.6958 - mae: 11.1785 - val_loss: 107.8281 - val_mae: 8.2303\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 202.9130 - mae: 11.0653 - val_loss: 105.2845 - val_mae: 8.1563\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 199.1568 - mae: 10.9515 - val_loss: 102.7721 - val_mae: 8.0818\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 195.4225 - mae: 10.8369 - val_loss: 100.2912 - val_mae: 8.0068\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 191.7062 - mae: 10.7216 - val_loss: 97.8443 - val_mae: 7.9316\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 188.0130 - mae: 10.6056 - val_loss: 95.4320 - val_mae: 7.8562\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 184.3470 - mae: 10.4890 - val_loss: 93.0544 - val_mae: 7.7805\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 180.7003 - mae: 10.3714 - val_loss: 90.7119 - val_mae: 7.7045\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 177.0791 - mae: 10.2530 - val_loss: 88.4051 - val_mae: 7.6284\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 173.4796 - mae: 10.1338 - val_loss: 86.1345 - val_mae: 7.5520\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 169.9075 - mae: 10.0139 - val_loss: 83.8971 - val_mae: 7.4753\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 166.3631 - mae: 9.8934 - val_loss: 81.6930 - val_mae: 7.3981\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 162.8443 - mae: 9.7720 - val_loss: 79.5308 - val_mae: 7.3210\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 159.3560 - mae: 9.6500 - val_loss: 77.4059 - val_mae: 7.2436\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 155.9024 - mae: 9.5338 - val_loss: 75.3178 - val_mae: 7.1660\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 152.4847 - mae: 9.4211 - val_loss: 73.2650 - val_mae: 7.0879\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 149.1023 - mae: 9.3081 - val_loss: 71.2495 - val_mae: 7.0096\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 145.7529 - mae: 9.2001 - val_loss: 69.2684 - val_mae: 6.9306\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 142.4377 - mae: 9.0916 - val_loss: 67.3228 - val_mae: 6.8510\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 139.1609 - mae: 8.9825 - val_loss: 65.4164 - val_mae: 6.7712\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 135.9251 - mae: 8.8729 - val_loss: 63.5449 - val_mae: 6.6909\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 132.7292 - mae: 8.7628 - val_loss: 61.7119 - val_mae: 6.6104\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 129.5527 - mae: 8.6513 - val_loss: 59.9196 - val_mae: 6.5297\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 126.4114 - mae: 8.5391 - val_loss: 58.1629 - val_mae: 6.4484\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 123.3060 - mae: 8.4258 - val_loss: 56.4447 - val_mae: 6.3669\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 120.2426 - mae: 8.3133 - val_loss: 54.7683 - val_mae: 6.2852\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 117.2249 - mae: 8.2032 - val_loss: 53.1331 - val_mae: 6.2033\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 114.2539 - mae: 8.0926 - val_loss: 51.5380 - val_mae: 6.1211\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 111.3373 - mae: 7.9820 - val_loss: 49.9885 - val_mae: 6.0391\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 108.4778 - mae: 7.8708 - val_loss: 48.4823 - val_mae: 5.9570\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 105.6743 - mae: 7.7598 - val_loss: 47.0170 - val_mae: 5.8749\n",
      "Test Loss: 104.1748, Test MAE: 8.1374\n",
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer with a single neuron for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}, Test MAE: {mae:.4f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# You can use 'predictions' to predict wind energy based on new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Subhang Mokkarala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted Wind Energy: 1.613121509552002\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "model.save('wind_energy_prediction_model.h5')\n",
    "\n",
    "# Load the saved model (if needed)\n",
    "loaded_model = tf.keras.models.load_model('wind_energy_prediction_model.h5')\n",
    "new_soil_temp = 25.0\n",
    "new_temp = 20.0\n",
    "new_pressure = 95848\n",
    "new_wind_speed = 1.4\n",
    "\n",
    "# Make predictions using new input data\n",
    "new_input_data = np.array([[new_soil_temp, new_temp, new_pressure, new_wind_speed]])  # Replace with your new data\n",
    "new_input_data = scaler.transform(new_input_data)  # Standardize the new input data\n",
    "\n",
    "# Predict wind energy\n",
    "predicted_wind_energy = model.predict(new_input_data)\n",
    "\n",
    "print(f'Predicted Wind Energy: {predicted_wind_energy[0][0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
