{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Model:\n",
    "\n",
    "Architecture: The previous model had a simpler architecture with only two hidden layers (32 and 16 neurons) and no dropout layers.\n",
    "Activation Function: It used ReLU activation functions for hidden layers.\n",
    "Regularization: It did not include dropout layers or other explicit forms of regularization.\n",
    "\n",
    "\n",
    "Updated Model:\n",
    "\n",
    "Architecture: The updated model has a more complex architecture with three hidden layers (64, 32, and 16 neurons) and includes dropout layers after the first two hidden layers.\n",
    "Activation Function: It also used ReLU activation functions for hidden layers.\n",
    "Regularization: It incorporates dropout layers with a dropout rate of 20% after the first two hidden layers. Dropout is a regularization technique that helps prevent overfitting by randomly deactivating a fraction of neurons during each training batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " date_hourly        0\n",
      "hourly          95593\n",
      "soil_temp1          1\n",
      "temp1               0\n",
      "solar_rd            0\n",
      "u10                 0\n",
      "v10              1105\n",
      "soil_temp           1\n",
      "temp                1\n",
      "pressure         1105\n",
      "wind_speed          0\n",
      "Wind_Energy         0\n",
      "dtype: int64\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 708.7911 - mae: 21.2200 - val_loss: 479.3664 - val_mae: 17.0705\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 707.8078 - mae: 21.1974 - val_loss: 478.5074 - val_mae: 17.0460\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 706.8310 - mae: 21.1750 - val_loss: 477.6753 - val_mae: 17.0220\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 705.8705 - mae: 21.1528 - val_loss: 476.8527 - val_mae: 16.9982\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 704.9260 - mae: 21.1309 - val_loss: 476.0284 - val_mae: 16.9743\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 703.9891 - mae: 21.1092 - val_loss: 475.2093 - val_mae: 16.9505\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 703.0578 - mae: 21.0877 - val_loss: 474.3926 - val_mae: 16.9265\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 702.1327 - mae: 21.0663 - val_loss: 473.5777 - val_mae: 16.9025\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 701.2196 - mae: 21.0453 - val_loss: 472.7903 - val_mae: 16.8793\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 700.3185 - mae: 21.0243 - val_loss: 472.0252 - val_mae: 16.8565\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 699.4416 - mae: 21.0037 - val_loss: 471.2698 - val_mae: 16.8338\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 698.5820 - mae: 20.9834 - val_loss: 470.5400 - val_mae: 16.8118\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 697.7227 - mae: 20.9631 - val_loss: 469.8017 - val_mae: 16.7895\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 696.8607 - mae: 20.9429 - val_loss: 469.0711 - val_mae: 16.7674\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 696.0154 - mae: 20.9228 - val_loss: 468.3431 - val_mae: 16.7451\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 695.1868 - mae: 20.9030 - val_loss: 467.6154 - val_mae: 16.7228\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 694.3594 - mae: 20.8839 - val_loss: 466.8883 - val_mae: 16.7004\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 693.5294 - mae: 20.8647 - val_loss: 466.1553 - val_mae: 16.6780\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 692.6954 - mae: 20.8455 - val_loss: 465.4518 - val_mae: 16.6560\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 691.8738 - mae: 20.8263 - val_loss: 464.7819 - val_mae: 16.6345\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 691.0599 - mae: 20.8080 - val_loss: 464.1522 - val_mae: 16.6138\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 690.2543 - mae: 20.7899 - val_loss: 463.5173 - val_mae: 16.5935\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 689.4672 - mae: 20.7719 - val_loss: 462.8850 - val_mae: 16.5730\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 688.6902 - mae: 20.7540 - val_loss: 462.2503 - val_mae: 16.5522\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 687.9311 - mae: 20.7362 - val_loss: 461.6268 - val_mae: 16.5316\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 687.1907 - mae: 20.7188 - val_loss: 461.0067 - val_mae: 16.5110\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 686.4597 - mae: 20.7015 - val_loss: 460.3987 - val_mae: 16.4904\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 685.7345 - mae: 20.6841 - val_loss: 459.7785 - val_mae: 16.4698\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 685.0000 - mae: 20.6665 - val_loss: 459.1474 - val_mae: 16.4490\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 684.2525 - mae: 20.6486 - val_loss: 458.5062 - val_mae: 16.4280\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 683.4942 - mae: 20.6304 - val_loss: 457.8416 - val_mae: 16.4065\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 682.7192 - mae: 20.6121 - val_loss: 457.1601 - val_mae: 16.3846\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 681.9394 - mae: 20.5937 - val_loss: 456.4681 - val_mae: 16.3625\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 681.1624 - mae: 20.5753 - val_loss: 455.7752 - val_mae: 16.3404\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 680.3587 - mae: 20.5567 - val_loss: 455.0617 - val_mae: 16.3180\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 679.5393 - mae: 20.5378 - val_loss: 454.3372 - val_mae: 16.2957\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 678.7178 - mae: 20.5190 - val_loss: 453.6033 - val_mae: 16.2729\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 677.8812 - mae: 20.4999 - val_loss: 452.8591 - val_mae: 16.2499\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 677.0397 - mae: 20.4808 - val_loss: 452.1044 - val_mae: 16.2266\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 676.1853 - mae: 20.4615 - val_loss: 451.3413 - val_mae: 16.2030\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 675.3221 - mae: 20.4421 - val_loss: 450.5711 - val_mae: 16.1793\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 674.4471 - mae: 20.4226 - val_loss: 449.7814 - val_mae: 16.1554\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 673.5531 - mae: 20.4043 - val_loss: 448.9748 - val_mae: 16.1312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 672.6346 - mae: 20.3859 - val_loss: 448.1571 - val_mae: 16.1066\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 671.7018 - mae: 20.3672 - val_loss: 447.3265 - val_mae: 16.0818\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 670.7393 - mae: 20.3480 - val_loss: 446.4824 - val_mae: 16.0565\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 669.7527 - mae: 20.3284 - val_loss: 445.6245 - val_mae: 16.0310\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 668.7406 - mae: 20.3087 - val_loss: 444.7538 - val_mae: 16.0051\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 667.7006 - mae: 20.2888 - val_loss: 443.8604 - val_mae: 15.9787\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 666.6431 - mae: 20.2685 - val_loss: 442.9521 - val_mae: 15.9518\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 665.5668 - mae: 20.2479 - val_loss: 442.0322 - val_mae: 15.9247\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 664.4699 - mae: 20.2270 - val_loss: 441.0962 - val_mae: 15.9002\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 663.3481 - mae: 20.2056 - val_loss: 440.1452 - val_mae: 15.8762\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 662.2001 - mae: 20.1837 - val_loss: 439.1798 - val_mae: 15.8519\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 661.0261 - mae: 20.1613 - val_loss: 438.1978 - val_mae: 15.8271\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 659.8297 - mae: 20.1385 - val_loss: 437.1899 - val_mae: 15.8017\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 658.6097 - mae: 20.1152 - val_loss: 436.1661 - val_mae: 15.7760\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 657.3584 - mae: 20.0912 - val_loss: 435.1262 - val_mae: 15.7498\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 656.0745 - mae: 20.0664 - val_loss: 434.0695 - val_mae: 15.7232\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 654.7617 - mae: 20.0406 - val_loss: 432.9719 - val_mae: 15.6958\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 653.4188 - mae: 20.0142 - val_loss: 431.8540 - val_mae: 15.6679\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 652.0400 - mae: 19.9869 - val_loss: 430.7183 - val_mae: 15.6396\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 650.6359 - mae: 19.9592 - val_loss: 429.5612 - val_mae: 15.6108\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 649.2025 - mae: 19.9308 - val_loss: 428.3818 - val_mae: 15.5851\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 647.7401 - mae: 19.9023 - val_loss: 427.1706 - val_mae: 15.5588\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 646.2531 - mae: 19.8733 - val_loss: 425.9109 - val_mae: 15.5318\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 644.7415 - mae: 19.8437 - val_loss: 424.6275 - val_mae: 15.5043\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 643.1990 - mae: 19.8133 - val_loss: 423.3242 - val_mae: 15.4763\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 641.6105 - mae: 19.7817 - val_loss: 422.0002 - val_mae: 15.4478\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 639.9904 - mae: 19.7493 - val_loss: 420.6557 - val_mae: 15.4189\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 638.3228 - mae: 19.7159 - val_loss: 419.2902 - val_mae: 15.3895\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 636.6071 - mae: 19.6816 - val_loss: 417.9012 - val_mae: 15.3594\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 634.8488 - mae: 19.6464 - val_loss: 416.4902 - val_mae: 15.3288\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 633.0609 - mae: 19.6105 - val_loss: 415.0580 - val_mae: 15.2977\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 631.2438 - mae: 19.5739 - val_loss: 413.6048 - val_mae: 15.2661\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 629.3973 - mae: 19.5367 - val_loss: 412.1305 - val_mae: 15.2339\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 627.5206 - mae: 19.4987 - val_loss: 410.6348 - val_mae: 15.2013\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 625.6144 - mae: 19.4601 - val_loss: 409.1180 - val_mae: 15.1682\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 623.6761 - mae: 19.4206 - val_loss: 407.5800 - val_mae: 15.1345\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 621.7076 - mae: 19.3804 - val_loss: 406.0209 - val_mae: 15.1003\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 619.7082 - mae: 19.3395 - val_loss: 404.4384 - val_mae: 15.0655\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 617.6786 - mae: 19.2978 - val_loss: 402.8311 - val_mae: 15.0301\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 615.6154 - mae: 19.2553 - val_loss: 401.2020 - val_mae: 14.9941\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 613.5159 - mae: 19.2120 - val_loss: 399.5504 - val_mae: 14.9575\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 611.3839 - mae: 19.1679 - val_loss: 397.8782 - val_mae: 14.9204\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 609.2204 - mae: 19.1231 - val_loss: 396.1837 - val_mae: 14.8828\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 607.0212 - mae: 19.0774 - val_loss: 394.4658 - val_mae: 14.8445\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 604.7896 - mae: 19.0310 - val_loss: 392.7244 - val_mae: 14.8055\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 602.5226 - mae: 18.9837 - val_loss: 390.9595 - val_mae: 14.7660\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 600.2219 - mae: 18.9356 - val_loss: 389.1699 - val_mae: 14.7258\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 597.8869 - mae: 18.8866 - val_loss: 387.3540 - val_mae: 14.6849\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 595.5194 - mae: 18.8368 - val_loss: 385.5149 - val_mae: 14.6433\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 593.1173 - mae: 18.7861 - val_loss: 383.6523 - val_mae: 14.6011\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 590.6843 - mae: 18.7346 - val_loss: 381.7662 - val_mae: 14.5583\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 588.2181 - mae: 18.6822 - val_loss: 379.8566 - val_mae: 14.5148\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 585.7194 - mae: 18.6289 - val_loss: 377.9207 - val_mae: 14.4706\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 583.1875 - mae: 18.5746 - val_loss: 375.9588 - val_mae: 14.4257\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 580.6215 - mae: 18.5194 - val_loss: 373.9713 - val_mae: 14.3801\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 578.0223 - mae: 18.4636 - val_loss: 371.9566 - val_mae: 14.3337\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 575.3895 - mae: 18.4085 - val_loss: 369.9183 - val_mae: 14.2866\n",
      "Test Loss: 510.9051, Test MAE: 15.4198\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data from Excel file\n",
    "data = pd.read_excel('Wind_Energy_Rayalaseema.xlsx')\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Remove rows with missing values (if desired)\n",
    "data = data.dropna()\n",
    "\n",
    "# Check for and remove duplicates (if desired)\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Outlier detection and handling (you can customize this)\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(data[['soil_temp', 'temp', 'pressure', 'wind_speed']]))\n",
    "threshold = 3\n",
    "outliers = (z_scores > threshold).all(axis=1)\n",
    "data = data[~outliers]\n",
    "# Split data into features (X) and target (y)\n",
    "X = data[['soil_temp', 'temp', 'pressure', 'wind_speed']].values\n",
    "y = data['Wind_Energy'].values.reshape(-1, 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}, Test MAE: {mae:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n",
      "Predicted Wind Energy: 30.03091812133789\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for new input data\n",
    "new_soil_temp_value = 28.0\n",
    "new_temp_value = 30.0  \n",
    "new_pressure_value = 98588\n",
    "new_wind_speed_value = 2.0  \n",
    "\n",
    "# Create an array with the new input data\n",
    "new_data = np.array([[new_soil_temp_value,new_temp_value, new_pressure_value, new_wind_speed_value]])\n",
    "\n",
    "# Standardize the new input data using the same scaler used during training\n",
    "new_data = scaler.transform(new_data)  # Standardize the new input data\n",
    "\n",
    "# Make predictions for the new input data\n",
    "predicted_wind_energy = model.predict(new_data)\n",
    "\n",
    "print(f'Predicted Wind Energy: {predicted_wind_energy[0][0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
